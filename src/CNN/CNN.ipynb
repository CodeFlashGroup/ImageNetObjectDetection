{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dimensions of our images.\n",
    "\n",
    "width_of_image, height_of_image = 150, 150\n",
    "\n",
    "\n",
    "\n",
    "training_data_dir = 'C:/Users/Shivani/Desktop/imagenet/train'\n",
    "validation_data_dir = 'C:/Users/Shivani/Desktop/imagenet/validation'\n",
    "\n",
    "#validation_data_dir = 'data/validation'\n",
    "epochs = 50\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 50\n",
    "batch_size = 16\n",
    "input_shape = (width_of_image, height_of_image, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mymodel = Sequential()\n",
    "\n",
    "mymodel.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "\n",
    "mymodel.add(Activation('relu'))\n",
    "\n",
    "mymodel.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mymodel.add(Conv2D(32, (3, 3)))\n",
    "\n",
    "mymodel.add(Activation('relu'))\n",
    "\n",
    "mymodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "\n",
    "mymodel.add(Conv2D(64, (3, 3)))\n",
    "\n",
    "mymodel.add(Activation('relu'))\n",
    "\n",
    "mymodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "\n",
    "mymodel.add(Flatten())\n",
    "\n",
    "mymodel.add(Dense(64))\n",
    "\n",
    "mymodel.add(Activation('relu'))\n",
    "\n",
    "mymodel.add(Dropout(0.5))\n",
    "\n",
    "mymodel.add(Dense(1))\n",
    "\n",
    "mymodel.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mymodel.compile(loss='binary_crossentropy',\n",
    "\n",
    "              optimizer='rmsprop',\n",
    "\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5416 images belonging to 2 classes.\n",
      "Found 1047 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "\n",
    "    rescale=1. / 255,\n",
    "\n",
    "    shear_range=0.2,\n",
    "\n",
    "    zoom_range=0.2,\n",
    "\n",
    "    horizontal_flip=True)\n",
    "\n",
    "\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "\n",
    "# only rescaling\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "\n",
    "    training_data_dir,\n",
    "\n",
    "    target_size=(width_of_image, height_of_image),\n",
    "\n",
    "    batch_size=batch_size,\n",
    "\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "\n",
    "    validation_data_dir,\n",
    "\n",
    "    target_size=(width_of_image, height_of_image),\n",
    "\n",
    "    batch_size=batch_size,\n",
    "\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "125/125 [==============================] - 181s 1s/step - loss: 0.1497 - acc: 0.9810 - val_loss: 0.2348 - val_acc: 0.9583\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 177s 1s/step - loss: 0.1216 - acc: 0.9810 - val_loss: 0.6727 - val_acc: 0.9583\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 181s 1s/step - loss: 0.1443 - acc: 0.9800 - val_loss: 0.4853 - val_acc: 0.9583\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 171s 1s/step - loss: 0.1582 - acc: 0.9815 - val_loss: 0.2529 - val_acc: 0.9583\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 177s 1s/step - loss: 0.1316 - acc: 0.9825 - val_loss: 0.1876 - val_acc: 0.9583\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 172s 1s/step - loss: 0.1845 - acc: 0.9800 - val_loss: 0.4407 - val_acc: 0.9583\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 175s 1s/step - loss: 0.1438 - acc: 0.9830 - val_loss: 0.2975 - val_acc: 0.9583\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 174s 1s/step - loss: 0.1352 - acc: 0.9790 - val_loss: 0.4027 - val_acc: 0.9583\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 161s 1s/step - loss: 0.1379 - acc: 0.9795 - val_loss: 0.1814 - val_acc: 0.9583\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 157s 1s/step - loss: 0.1531 - acc: 0.9790 - val_loss: 0.2145 - val_acc: 0.9583\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 155s 1s/step - loss: 0.1167 - acc: 0.9840 - val_loss: 0.4038 - val_acc: 0.9583\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 163s 1s/step - loss: 0.1523 - acc: 0.9820 - val_loss: 0.4726 - val_acc: 0.9583\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 176s 1s/step - loss: 0.2134 - acc: 0.9810 - val_loss: 0.6716 - val_acc: 0.9583\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 208s 2s/step - loss: 0.2821 - acc: 0.9825 - val_loss: 0.6716 - val_acc: 0.9583\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 164s 1s/step - loss: 0.2498 - acc: 0.9845 - val_loss: 0.6716 - val_acc: 0.9583\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 172s 1s/step - loss: 0.3063 - acc: 0.9810 - val_loss: 0.6716 - val_acc: 0.9583\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 170s 1s/step - loss: 0.3868 - acc: 0.9760 - val_loss: 0.6716 - val_acc: 0.9583\n",
      "Epoch 18/50\n",
      " 93/125 [=====================>........] - ETA: 41s - loss: 0.1625 - acc: 0.9899"
     ]
    }
   ],
   "source": [
    "mymodel.fit_generator(\n",
    "\n",
    "    train_generator,\n",
    "\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "\n",
    "    validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import csv\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from scipy.misc import imresize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_labels(model):\n",
    "    \"\"\"writes test image labels and predictions to csv\"\"\"\n",
    "    test_data_dir = \"C:/Users/Shivani/Desktop/imagenet/test1/\"\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        shuffle=False,\n",
    "        class_mode=\"binary\")\n",
    "\n",
    "   \n",
    "\n",
    "    with open(\"prediction.csv\", \"w\") as f:\n",
    "        p_writer = csv.writer(f, delimiter=',', lineterminator='\\n')\n",
    "        for _, _, imgs in os.walk(test_data_dir):\n",
    "            for im in imgs:\n",
    "                pic_id = im.split(\".\")[0]\n",
    "                img = load_img(test_data_dir + im)\n",
    "                #img = imresize(img, size=(img_width, img_height))\n",
    "                #test_x = img_to_array(img).reshape(3, img_width, img_height)\n",
    "                #test_x = test_x.reshape((1,) + test_x.shape)\n",
    "                test_generator = test_datagen.flow(img,\n",
    "                                                   batch_size=1,\n",
    "                                                   shuffle=False)\n",
    "                prediction = model.predict_generator(test_generator, 1)\n",
    "                p_writer.writerow([pic_id, prediction])\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "('Input data in `NumpyArrayIterator` should have rank 4. You passed an array with shape', (284, 150, 3))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-d382e0422d03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprediction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpredict_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-82-1efabe6a9cab>\u001b[0m in \u001b[0;36mpredict_labels\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     23\u001b[0m                 test_generator = test_datagen.flow(img,\n\u001b[0;32m     24\u001b[0m                                                    \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                                                    shuffle=False)\n\u001b[0m\u001b[0;32m     26\u001b[0m                 \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[0mp_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpic_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Shivani\\Anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36mflow\u001b[1;34m(self, x, y, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0msave_to_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msave_to_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m             \u001b[0msave_prefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msave_prefix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             save_format=save_format)\n\u001b[0m\u001b[0;32m    494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m     def flow_from_directory(self, directory,\n",
      "\u001b[1;32mC:\\Users\\Shivani\\Anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, image_data_generator, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format)\u001b[0m\n\u001b[0;32m    845\u001b[0m             raise ValueError('Input data in `NumpyArrayIterator` '\n\u001b[0;32m    846\u001b[0m                              \u001b[1;34m'should have rank 4. You passed an array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m                              'with shape', self.x.shape)\n\u001b[0m\u001b[0;32m    848\u001b[0m         \u001b[0mchannels_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'channels_last'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchannels_axis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: ('Input data in `NumpyArrayIterator` should have rank 4. You passed an array with shape', (284, 150, 3))"
     ]
    }
   ],
   "source": [
    "prediction=predict_labels(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
